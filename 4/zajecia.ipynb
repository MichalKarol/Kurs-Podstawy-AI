{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework - Zapoznajmy się z DVC, PyTorch Lightning oraz Wandb\n",
    "\n",
    "Organizator: Koło naukowe BioMedicalAI  \n",
    "![biomedical.svg](biomedical.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DVC (Data Version Control)\n",
    "Narzędzie do wersjonowania danych, modeli ze wsparciem pipelienowania i wersjonowania eksperymentów - Git dla danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Uruchomienie MINIO\n",
    "# W katalogu 4 wywołaj\n",
    "!docker compose up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# W osobnej sesji terminala w ścieżce głównego katalogu z kursem\n",
    "\n",
    "# Inicjalizacja repozytorium\n",
    "!dvc init\n",
    "!dvc config hydra.enabled True\n",
    "\n",
    "# Dodanie datasetu\n",
    "!dvc add 4/American_Housing_Data_20231209.csv\n",
    "\n",
    "# Dodanie serwera remote\n",
    "!dvc remote add -d myremote s3://kursbucket\n",
    "!dvc remote modify myremote endpointurl http://$MINIO_IP:9000\n",
    "!dvc remote modify --local myremote access_key_id 'minio'\n",
    "!dvc remote modify --local myremote secret_access_key 'minio123'\n",
    "\n",
    "# Upload datasetu\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Daje to nam możliwość pobrania datasetu\n",
    "!rm 4/American_Housing_Data_20231209.csv\n",
    "!dvc pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning\n",
    "Framework oparty o Pytorch, upraszcza pracę z Pytorch poprzez abstrakcję powtarzalnego kodu niezwiązanego z konkretnym modelem (np. zerowanie gradientów, aplikowanie optymalizacji, kopiowanie danych na urządzenia). Pytorch buduje graf wywołań, dając leniwie ewaluowany kod. Dodatkowo, z zależności od zastosowanego akceleratora graf wywołań może zostać zoptymalizowany pod daną architekturę."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja popularności piosenki na podstawie jej parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer, MinMaxScaler, OneHotEncoder, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./American_Housing_Data_20231209.csv\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizualizacja poszczególnych kolumn na wykresach\n",
    "for column in df.drop(\"Address\", axis=1).columns:\n",
    "    if column in [\"City\", \"State\", \"County\", \"Zip Code\"]:\n",
    "        sns.histplot(df, x=column)\n",
    "    else:\n",
    "        sns.kdeplot(df, x=column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataModule\n",
    "class HouseDataModule():\n",
    "    class HouseDataset(Dataset):\n",
    "        def __init__(self, x, y):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "            assert len(self.x) == len(self.y), \"Number of values and labels are not equal\"\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.x)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __init__(self, data_path, val_split, test_split, seed):\n",
    "        dataset = pd.read_csv(data_path)\n",
    "        dataset.drop_duplicates(inplace=True)\n",
    "        dataset.dropna(inplace=True)\n",
    "        dataset = dataset.drop(\"Address\", axis=1)\n",
    "        y = dataset[\"Price\"].to_numpy().astype(float).reshape(-1, 1)\n",
    "        X = dataset.drop(\"Price\", axis=1)\n",
    "        X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=test_split, random_state=seed)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=(val_split / (1 - test_split)), random_state=seed) \n",
    "        \n",
    "        y_scaler = RobustScaler()\n",
    "        self.y_train = y_scaler.fit_transform(y_train)\n",
    "        self.y_val = y_scaler.transform(y_val)\n",
    "        self.y_test = y_scaler.transform(y_test)\n",
    "\n",
    "\n",
    "        ct = ColumnTransformer([\n",
    "            ('numerical', RobustScaler(), [\n",
    "                'Beds', \n",
    "                'Living Space',\n",
    "                \"Zip Code Population\",\n",
    "                \"Zip Code Density\",\n",
    "                \"Median Household Income\",\n",
    "                'Latitude',\n",
    "                \"Longitude\"\n",
    "            ]),\n",
    "            ('categories', OneHotEncoder(), [\"State\"]),\n",
    "        ])\n",
    "\n",
    "        self.x_train = ct.fit_transform(X_train).toarray()\n",
    "        self.x_val = ct.transform(X_val).toarray()\n",
    "        self.x_test = ct.fit_transform(X_test).toarray()\n",
    "        print(\"Example\", self.x_test[0], self.y_test[0])\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return HouseDataModule.HouseDataset(self.x_train, self.y_train)\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return HouseDataModule.HouseDataset(self.x_val, self.y_val)\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return HouseDataModule.HouseDataset(self.x_test, self.y_test)\n",
    "\n",
    "\n",
    "datamodule = HouseDataModule(\"./American_Housing_Data_20231209.csv\", 0.1, 0.2, 21)\n",
    "# INFO: batchsize i epoka\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(datamodule.train, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count() -1)\n",
    "val_dataloader = DataLoader(datamodule.val, batch_size=batch_size, num_workers=os.cpu_count() -1)\n",
    "test_dataloader = DataLoader(datamodule.test, batch_size=batch_size, num_workers=os.cpu_count() -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "import lightning as L\n",
    "import torchmetrics as TM\n",
    "\n",
    "\n",
    "# Definiujemy nasz moduł z kodem do uczenia modelu\n",
    "class LightningRegression(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(36, 64, dtype=torch.float64), #INFO: Czemu 36?\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 64, dtype=torch.float64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 32, dtype=torch.float64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 1, dtype=torch.float64),\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        loss = nn.functional.mse_loss(y_pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        self.log(\"val_r2\", TM.functional.r2_score(y_pred, y))\n",
    "        self.log(\"val_mse\", TM.functional.mean_squared_error(y_pred, y), prog_bar=True)\n",
    "        self.log(\"val_mae\", TM.functional.mean_absolute_error(y_pred, y))\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        self.log(\"test_r2\", TM.functional.r2_score(y_pred, y))\n",
    "        self.log(\"test_mse\", TM.functional.mean_squared_error(y_pred, y), prog_bar=True)\n",
    "        self.log(\"test_mae\", TM.functional.mean_absolute_error(y_pred, y))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "regression = LightningRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list  = []\n",
    "y_preds = []\n",
    "for x, y in iter(test_dataloader):\n",
    "    y_list.extend(y.numpy()[0])\n",
    "    y_pred = regression.model(x)\n",
    "    y_preds.extend(y_pred.detach().numpy()[0])\n",
    "\n",
    "sns.scatterplot(x=y_list, y=y_list)\n",
    "sns.scatterplot(x=y_list, y=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=25)\n",
    "trainer.test(regression, test_dataloader)\n",
    "trainer.fit(model=regression, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "trainer.test(regression, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list  = []\n",
    "y_preds = []\n",
    "for x, y in iter(test_dataloader):\n",
    "    y_list.extend(y.numpy()[0])\n",
    "    y_pred = regression.model(x)\n",
    "    y_preds.extend(y_pred.detach().numpy()[0])\n",
    "\n",
    "sns.scatterplot(x=y_list, y=y_list)\n",
    "sns.scatterplot(x=y_list, y=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB (Weights and Biases)\n",
    "Narzędzie do trackowania postępów uczenia, hiperparametrów eksperymentów, zapisywania wyściowych modeli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "with wandb.init(project=\"Kurs AI\") as run:\n",
    "    wandb_logger = WandbLogger(log_model=\"all\", name=\"Kurs AI\", save_dir=\"logs\")\n",
    "    wandb_logger.experiment.config[\"max_epochs\"] = 10\n",
    "    wandb_logger.experiment.config[\"batch_size\"] = batch_size\n",
    "    trainer = L.Trainer(max_epochs=10, logger=wandb_logger)\n",
    "    trainer.fit(model=regression, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining\n",
    "DVC pozwala na utworzenie pipelinów eksperymentów. Mechanizm opiera się o plik dvc.yaml gdzie zapisujemy kroki i zależności kroków w celu utworzenia grafu wykonania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Wyświetl graf wykonania\n",
    "!dvc dag\n",
    "\n",
    "# Uruchom eksperymenty\n",
    "!dvc exp run\n",
    "\n",
    "# Uruchom eksperymenty z konkretnym parametrem\n",
    "!dvc exp run  --set-param 'batch_size=32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosta klasyfikacja (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test = datasets.MNIST('../data', train=False, download=True, transform=transforms.ToTensor())\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizualizacja MNIST\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train), size=(1,)).item()\n",
    "    img, label = train[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(train[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningClassification(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_flatten = x.reshape((x.shape[0], x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "        y_pred = self.model(x_flatten)\n",
    "        loss = nn.functional.cross_entropy(y_pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        x, y = batch\n",
    "        x_flatten = x.reshape((x.shape[0], x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "        y_pred = self.model(x_flatten)\n",
    "        self.log(\"val_accuracy\", TM.functional.accuracy(y_pred, y, task=\"multiclass\", num_classes=10))\n",
    "        self.log(\"val_precision\", TM.functional.precision(y_pred, y, task=\"multiclass\", num_classes=10), prog_bar=True)\n",
    "        self.log(\"val_matthews_corrcoef\", TM.functional.matthews_corrcoef(y_pred, y, task=\"multiclass\", num_classes=10), prog_bar=True)\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        x, y = batch\n",
    "        x_flatten = x.reshape((x.shape[0], x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "        y_pred = self.model(x_flatten)\n",
    "        self.log(\"test_accuracy\", TM.functional.accuracy(y_pred, y, task=\"multiclass\", num_classes=10))\n",
    "        self.log(\"test_precision\", TM.functional.precision(y_pred, y, task=\"multiclass\", num_classes=10), prog_bar=True)\n",
    "        self.log(\"test_matthews_corrcoef\", TM.functional.matthews_corrcoef(y_pred, y, task=\"multiclass\", num_classes=10), prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "classifier = LightningClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count() -1)\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=os.cpu_count() -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=25)\n",
    "trainer.fit(model=classifier, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "trainer.test(classifier, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizualizacja wyników klasyfikatora MNIST\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(test), size=(1,)).item()\n",
    "    img, label = test[sample_idx]\n",
    "    label_pred_vector = classifier.model(img.reshape(1, 28*28))\n",
    "    label_pred = torch.argmax(label_pred_vector, axis=1)\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f\"{label} / {label_pred.item()}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ankieta\n",
    "![\"Ankieta\"](./ankieta.png)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
